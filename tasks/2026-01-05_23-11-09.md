## 1) Critical issues

### AI DB: missing core PRAGMAs (real risk of “database is locked” + sluggish writes)

`init_ai_db()` opens the DB and creates schema, but does **not** set WAL, busy timeout, or foreign key enforcement. Notes explicitly enables WAL; AI doesn’t.

What this means in practice:

* **More lock contention** and more frequent “database is locked” errors under multi-window / multi-threaded access.
* **Worse write latency** (especially for message saves) compared to WAL.
* Your `FOREIGN KEY ... ON DELETE CASCADE` is currently **not enforced** unless you enable `PRAGMA foreign_keys=ON` per connection.

**Fix:** standardize a “default pragmas” block and apply it in *every* DB init. At minimum:

* `journal_mode=WAL`
* `synchronous=NORMAL` (often a good app tradeoff in WAL mode)
* `foreign_keys=ON`
* `busy_timeout=…` (e.g. 500–2000ms)

### AI FTS trigger churn bug (this will bite you hard)

In `src/ai/storage.rs`, your chat FTS triggers are:

```sql
CREATE TRIGGER IF NOT EXISTS chats_au AFTER UPDATE ON chats BEGIN ...
```

But your `save_message_internal()` updates `chats.updated_at` on every message insert. That means **every message causes a DELETE+INSERT into `chats_fts`**, even though only `title` is indexed.

This is a straight performance bug: unnecessary FTS maintenance on the hottest path.

**Fix:** change to `AFTER UPDATE OF title` (and drop/recreate existing triggers during migration, because `IF NOT EXISTS` won’t replace wrong ones).

Similarly, for messages:

* `messages_fts` only indexes `content`, so `messages_au` should be `AFTER UPDATE OF content`.

### Notes search is fragile: `MATCH` can error on user input

`search_notes()` directly passes user input to `notes_fts MATCH ?1`. FTS5 query syntax breaks on special characters fairly easily (quotes, colons, etc.). Your AI module already had to add sanitization + fallback, but notes doesn’t.

So a user typing something like an email address, quotes, or certain punctuation can cause search to error.

**Fix:** reuse the same pattern you used in AI:

* sanitize or quote the query
* if FTS errors, fall back to `LIKE` on title/content (or a simplified FTS query)

### FTS migration correctness: no backfill/rebuild path

Both Notes and AI create FTS tables + triggers, but there’s no migration logic to:

* detect “FTS table exists but is empty / out of sync”
* rebuild FTS when introduced on an existing DB

This can produce **silent bad search** (no results) rather than an explicit error, and your fallback only triggers on *error*, not “FTS returned 0”.

**Fix:** use `PRAGMA user_version` migrations and add a rebuild step when upgrading to the version that introduces/changes FTS:

* `INSERT INTO notes_fts(notes_fts) VALUES('rebuild');`
* same for chats/messages fts

### Mutex poisoning makes DB permanently “dead” after a panic

Every `.lock().map_err(|e| anyhow!("DB lock error: {}", e))?` means:

* if any thread panics while holding the mutex, the mutex becomes poisoned
* every future DB operation errors forever

For a desktop app, that’s a nasty failure mode (one bug → persistent broken storage until restart).

**Fix options:**

* Prefer `parking_lot::Mutex` (no poisoning, faster)
* Or recover: `let conn = db.lock().unwrap_or_else(|e| e.into_inner());`

---

## 2) Performance concerns

### Hot path: message save = 2 autocommit transactions

`save_message_internal()` runs:

1. insert/update into `messages`
2. update `chats.updated_at`

Without an explicit transaction, that’s typically **two separate autocommit transactions** (two journal commits / fsync-ish work). Under load, that adds latency and can create UI jank if you ever call it near UI code.

**Fix:** wrap both statements in one transaction.

### Menu cache holds the DB lock while doing heavy JSON work

In `menu_cache.rs` you lock the DB, then serialize/deserialize JSON while still holding the lock.

Examples:

* `get_cached_menu()` parses JSON under lock
* `set_cached_menu()` serializes JSON under lock

This increases contention and can block unrelated operations.

**Fix:** scope the lock tightly: read/write the JSON string under lock, then drop the guard and do JSON work outside.

### FTS query shape in AI likely causes extra work

Your AI FTS query uses multiple `LEFT JOIN`s with `DISTINCT` across chats/messages/FTS tables. That can explode intermediate rows (many messages per chat) and force DISTINCT work.

A more efficient shape is usually:

* one subquery for matching chat rowids from `chats_fts`
* one subquery for matching chat_ids from `messages_fts` joined to `messages`
* `UNION` them, then fetch chats by id/rowid

### Statement prepare overhead

Most functions use `conn.prepare(...)` each call. For high-frequency queries (search, list chats, list notes), switching to `prepare_cached` can be a cheap win. You already use a single connection; cached statements will actually pay off.

---

## 3) API design feedback

### Yes: a generic `DatabaseManager` is worth it — but keep it small

You don’t need a “full ORM” abstraction. You need:

* canonical DB path logic
* consistent PRAGMA config
* one-time init + migrations
* “run closure with locked connection” helper (and optionally “run in transaction”)

That eliminates ~80% of the duplication without forcing every module into a single generic CRUD trait.

### Trait-based CRUD abstraction: be careful (it can get leaky fast)

A `Repository<T>` trait sounds nice until:

* queries diverge (pinned notes, different sorting, joins, FTS ranking)
* you need module-specific indexes or schema tweaks

What *does* generalize cleanly:

* soft delete / restore / list active / list deleted patterns (parameterized by table/column names)
* timestamp helpers
* FTS install/rebuild helpers
* common `with_conn` / `with_txn`

If you want a trait, make it “table metadata + common operations”, not “generic CRUD for everything”.

Example direction:

* `SoftDeleteTable { TABLE, ID_COL, UPDATED_AT_COL, DELETED_AT_COL }`
* `fn soft_delete(&self, id: &str)`, etc.

### Unified DB file vs separate DB files

Given your constraints (launcher must stay snappy; clipboard/history can be write-heavy; multi-window):

* **Keep separate SQLite files** for isolation and to avoid “one hot table blocks everything”.
* Unify the *code*, not necessarily the *physical database*.

If you ever want a single DB later, do it for a user-facing feature like “global search across everything” — but it will increase contention and blast radius. For now, separate files are the safer performance choice.

---

## 4) Simplification opportunities

### Replace lock boilerplate entirely

Best simplification: stop calling `.lock().map_err(...)` everywhere.

Either:

* use `parking_lot::Mutex` and lock is infallible
* or centralize it in `with_conn()` and never write it again

### Remove redundant “already initialized” checks

All three modules do:

```rust
if DB.get().is_some() { return Ok(()); }
```

Then later `get_or_init` / `set`. This is duplicative. `OnceLock::get_or_try_init` can handle the whole init atomically and only once.

### Centralize:

* `~/.scriptkit/db` base dir
* “ensure directory exists”
* PRAGMAs
* migration/version management
* datetime parsing helpers
* FTS trigger generation/install

---

## 5) Specific recommendations with concrete code changes

### A. Add a `src/db/mod.rs` that solves 80% of duplication

Here’s a “small but powerful” shape that fits your current patterns and keeps compatibility.

```rust
// src/db/mod.rs
use anyhow::{Context, Result};
use rusqlite::Connection;
use std::path::{Path, PathBuf};
use std::sync::OnceLock;

pub fn kit_db_dir() -> PathBuf {
    let home = dirs::home_dir()
        .unwrap_or_else(|| PathBuf::from(".scriptkit")); // keep your fallback behavior
    home.join(".scriptkit").join("db")
}

pub fn db_path(filename: &str) -> PathBuf {
    kit_db_dir().join(filename)
}

#[derive(Clone, Copy)]
pub struct DbPragmas {
    pub wal: bool,
    pub foreign_keys: bool,
    pub busy_timeout_ms: u64,
    pub synchronous_normal: bool,
}

impl DbPragmas {
    pub const fn default_app() -> Self {
        Self {
            wal: true,
            foreign_keys: true,
            busy_timeout_ms: 1000,
            synchronous_normal: true,
        }
    }

    pub fn apply(&self, conn: &Connection) -> Result<()> {
        if self.wal {
            conn.execute_batch("PRAGMA journal_mode=WAL;")
                .context("Failed to enable WAL")?;
        }
        if self.synchronous_normal {
            conn.execute_batch("PRAGMA synchronous=NORMAL;")
                .context("Failed to set synchronous")?;
        }
        if self.foreign_keys {
            conn.execute_batch("PRAGMA foreign_keys=ON;")
                .context("Failed to enable foreign_keys")?;
        }

        // rusqlite has a busy_timeout helper; but execute_batch is fine too.
        conn.busy_timeout(std::time::Duration::from_millis(self.busy_timeout_ms))
            .context("Failed to set busy_timeout")?;

        Ok(())
    }
}

// Choose one:
// - parking_lot::Mutex is best for this app
// - or keep std::sync::Mutex and recover from poisoning in with_conn
pub type DbConn = std::sync::Arc<parking_lot::Mutex<Connection>>;

pub struct DatabaseManager {
    filename: &'static str,
    pragmas: DbPragmas,
    conn: OnceLock<DbConn>,
    init: fn(&Connection) -> Result<()>,
}

impl DatabaseManager {
    pub const fn new(
        filename: &'static str,
        pragmas: DbPragmas,
        init: fn(&Connection) -> Result<()>,
    ) -> Self {
        Self {
            filename,
            pragmas,
            conn: OnceLock::new(),
            init,
        }
    }

    pub fn init(&'static self) -> Result<()> {
        self.conn.get_or_try_init(|| {
            let path = db_path(self.filename);
            ensure_parent_dir(&path)?;

            let conn = Connection::open(&path)
                .with_context(|| format!("Failed to open db: {}", path.display()))?;

            self.pragmas.apply(&conn)
                .with_context(|| format!("Failed to apply pragmas: {}", self.filename))?;

            (self.init)(&conn)
                .with_context(|| format!("Failed to init schema: {}", self.filename))?;

            Ok(std::sync::Arc::new(parking_lot::Mutex::new(conn)))
        })?;

        Ok(())
    }

    pub fn with_conn<T>(&'static self, f: impl FnOnce(&mut Connection) -> Result<T>) -> Result<T> {
        let db = self
            .conn
            .get()
            .ok_or_else(|| anyhow::anyhow!("Database not initialized: {}", self.filename))?;

        let mut guard = db.lock();
        f(&mut guard)
    }

    pub fn with_txn<T>(&'static self, f: impl FnOnce(&rusqlite::Transaction) -> Result<T>) -> Result<T> {
        self.with_conn(|conn| {
            let txn = conn.transaction().context("Failed to start transaction")?;
            let out = f(&txn)?;
            txn.commit().context("Failed to commit transaction")?;
            Ok(out)
        })
    }
}

fn ensure_parent_dir(path: &Path) -> Result<()> {
    if let Some(parent) = path.parent() {
        std::fs::create_dir_all(parent)
            .with_context(|| format!("Failed to create db dir: {}", parent.display()))?;
    }
    Ok(())
}
```

**Why this helps immediately:**

* one place for DB dir + paths
* consistent pragmas everywhere
* `with_conn` removes all lock boilerplate
* `with_txn` gives you a clean way to fix multi-statement hot paths

### B. Migrate one module (menu cache) first: minimal diff

```rust
// src/menu_cache.rs
use crate::db::{DatabaseManager, DbPragmas};

static MENU_DB: DatabaseManager = DatabaseManager::new(
    "menu-cache.sqlite",
    DbPragmas::default_app(), // or a tuned version
    init_menu_schema,
);

fn init_menu_schema(conn: &rusqlite::Connection) -> anyhow::Result<()> {
    conn.execute_batch(
        r#"
        CREATE TABLE IF NOT EXISTS menu_cache (
            bundle_id TEXT PRIMARY KEY,
            menu_json TEXT NOT NULL,
            last_scanned INTEGER NOT NULL,
            app_version TEXT
        );
        CREATE INDEX IF NOT EXISTS idx_menu_cache_last_scanned ON menu_cache(last_scanned);
        "#,
    )?;
    Ok(())
}

pub fn init_menu_cache_db() -> anyhow::Result<()> {
    MENU_DB.init()
}
```

Then implement operations via `MENU_DB.with_conn(...)`.

### C. Fix menu cache lock scope (concrete changes)

**Before** you were deserializing under lock. Change to:

```rust
pub fn get_cached_menu(bundle_id: &str) -> Result<Option<Vec<MenuBarItem>>> {
    let json_opt: Option<String> = MENU_DB.with_conn(|conn| {
        conn.query_row(
            "SELECT menu_json FROM menu_cache WHERE bundle_id = ?1",
            params![bundle_id],
            |row| row.get(0),
        )
        .optional()
        .context("Failed to query menu cache")
    })?;

    let Some(json) = json_opt else {
        return Ok(None);
    };

    // JSON work outside the DB lock:
    let items: Vec<MenuBarItem> =
        serde_json::from_str(&json).context("Failed to deserialize menu items")?;
    Ok(Some(items))
}

pub fn set_cached_menu(bundle_id: &str, items: &[MenuBarItem], app_version: Option<&str>) -> Result<()> {
    let menu_json = serde_json::to_string(items).context("Failed to serialize menu items")?;
    let timestamp = current_timestamp();

    MENU_DB.with_conn(|conn| {
        conn.execute(
            r#"
            INSERT INTO menu_cache (bundle_id, menu_json, last_scanned, app_version)
            VALUES (?1, ?2, ?3, ?4)
            ON CONFLICT(bundle_id) DO UPDATE SET
                menu_json = excluded.menu_json,
                last_scanned = excluded.last_scanned,
                app_version = excluded.app_version
            "#,
            params![bundle_id, menu_json, timestamp, app_version],
        )
        .context("Failed to save menu cache")?;
        Ok(())
    })
}
```

### D. Fix AI: add pragmas + fix FTS triggers + wrap message save in a transaction

#### 1) Enable WAL/foreign_keys/busy_timeout in AI init

Once you adopt `DatabaseManager`, this is automatic. If you don’t yet, at least add:

```rust
conn.execute_batch(
    r#"
    PRAGMA journal_mode=WAL;
    PRAGMA synchronous=NORMAL;
    PRAGMA foreign_keys=ON;
    "#,
)?;
conn.busy_timeout(std::time::Duration::from_millis(1000))?;
```

#### 2) Fix chat/message FTS triggers to only update on indexed columns

In AI schema SQL, replace:

```sql
CREATE TRIGGER IF NOT EXISTS chats_au AFTER UPDATE ON chats BEGIN ...
```

with something like:

```sql
DROP TRIGGER IF EXISTS chats_au;

CREATE TRIGGER chats_au AFTER UPDATE OF title ON chats BEGIN
    INSERT INTO chats_fts(chats_fts, rowid, title)
    VALUES('delete', OLD.rowid, OLD.title);
    INSERT INTO chats_fts(rowid, title)
    VALUES (NEW.rowid, NEW.title);
END;
```

And for messages:

```sql
DROP TRIGGER IF EXISTS messages_au;

CREATE TRIGGER messages_au AFTER UPDATE OF content ON messages BEGIN
    INSERT INTO messages_fts(messages_fts, rowid, content)
    VALUES('delete', OLD.rowid, OLD.content);
    INSERT INTO messages_fts(rowid, content)
    VALUES (NEW.rowid, NEW.content);
END;
```

#### 3) Make message save atomic + cheaper with one transaction

```rust
pub fn save_message(message: &Message) -> Result<()> {
    let db = get_db()?;
    let mut conn = db.lock().map_err(|e| anyhow::anyhow!("DB lock error: {}", e))?;

    let tx = conn.transaction().context("Failed to start transaction")?;

    tx.execute(
        r#"
        INSERT INTO messages (id, chat_id, role, content, created_at, tokens_used)
        VALUES (?1, ?2, ?3, ?4, ?5, ?6)
        ON CONFLICT(id) DO UPDATE SET
            content = excluded.content,
            tokens_used = excluded.tokens_used
        "#,
        params![...],
    )?;

    let now = Utc::now().to_rfc3339();
    tx.execute(
        "UPDATE chats SET updated_at = ?2 WHERE id = ?1",
        params![message.chat_id.as_str(), now],
    )?;

    tx.commit().context("Failed to commit message save")?;
    Ok(())
}
```

### E. Fix notes search robustness (copy AI’s “FTS or LIKE” idea)

A minimal practical patch:

* sanitize query for FTS (quote it, escape quotes)
* attempt FTS; if sqlite returns error, fall back to LIKE

That prevents user-typed junk from breaking search.

### F. Add shared datetime helpers (and stop repeating fallback logic)

Put this in `src/db/datetime.rs`:

```rust
use chrono::{DateTime, Utc};

pub fn parse_rfc3339_or_now(s: &str) -> DateTime<Utc> {
    DateTime::parse_from_rfc3339(s)
        .map(|dt| dt.with_timezone(&Utc))
        .unwrap_or_else(|_| Utc::now())
}

pub fn parse_rfc3339_opt(s: Option<String>) -> Option<DateTime<Utc>> {
    s.and_then(|s| DateTime::parse_from_rfc3339(&s).ok().map(|dt| dt.with_timezone(&Utc)))
}
```

Then row mappers become shorter and consistent.

### G. FTS5 helper: prefer a helper function (not a macro) + migration-based trigger updates

A helper is the sweet spot:

* zero runtime cost where it matters (runs once at init/migration)
* avoids macros that get gnarly with SQL formatting
* lets you bake in “update only on these columns” to avoid churn

If you do this, also add migrations via `user_version` so you can safely:

* drop/recreate triggers when you change them
* rebuild indexes when needed

---

## Answers to your “Key Questions” (direct)

1. **Create a generic `DatabaseManager`?**
   Yes. Do it. Keep it minimal: path + pragmas + init + with_conn/with_txn + migrations. That kills the duplication without locking you into a leaky “ORM”.

2. **Best trait-based abstraction for CRUD?**
   Avoid a universal CRUD trait. Use small reusable helpers:

* `SoftDeleteTable` metadata + common methods (optional)
* shared datetime parsing
* `with_txn` for multi-step ops
* FTS install/rebuild helpers
  Keep module-specific queries module-specific.

3. **Single unified database vs separate SQLite files?**
   Keep separate files (especially if clipboard/app launcher caches are write-heavy). You get better isolation and lower contention. Unify *code*, not the DB file, unless you have a compelling cross-feature query requirement.

4. **FTS5 trigger generation: macro vs helper vs templating?**
   Use a helper that generates/executes SQL (runtime string is fine). Pair it with migrations so you can update triggers safely. Macros add complexity with little benefit here.

5. **Safest migration path?**

* Keep filenames/paths unchanged.
* Add `PRAGMA user_version` migrations per DB.
* Apply pragmas on open (safe).
* For FTS trigger changes: migration step that drops/recreates triggers + rebuilds FTS if needed.
* Migrate one module at a time behind the same public API functions so scripts/users never notice.

If you want, paste one more module (clipboard history or app launcher cache) and I’ll show exactly how the `DatabaseManager + with_txn + migrations` pattern handles the “write-heavy” case without harming UI responsiveness.
