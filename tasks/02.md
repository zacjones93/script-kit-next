Below is a straight, actionable review based on what’s *actually visible* in the packed file. One caveat: a lot of the important logic lives behind `include!("app_impl.rs")`, `include!("render_script_list.rs")`, etc., so I can’t audit those parts for correctness/perf. But even in `main.rs` you already have several “this will bite you” issues, and the structure you’re using explains the state explosion you’re seeing.

---

## 1. Critical issues

### 1) **You clone `current_view` on every render — and some variants carry big `Vec`s**

In `Render for ScriptListApp` you do:

```rust
let current_view = self.current_view.clone();
let main_content: AnyElement = match current_view { ... }
```

But several `AppView` variants own large vectors:

* `ClipboardHistoryView { entries: Vec<...>, ... }`
* `AppLauncherView { apps: Vec<...>, ... }`
* `WindowSwitcherView { windows: Vec<...>, ... }`

That means you’re cloning **those entire lists every frame** while that view is active. That is absolutely incompatible with “instant open” + “60fps scrolling” once those lists get even moderately large. This one is not theoretical — it will show up as allocator churn and frame time spikes.

**Fix direction:** `AppView` should not own bulk data. It should own *only view-local state* (filter string, selection, scroll, etc.) and reference bulk data through an `Entity<Model>` or other stable store (details below).

---

### 2) **You compute debug overlay bounds every frame even when the grid is off**

You compute:

```rust
let component_bounds = self.build_component_bounds(window_size);
```

unconditionally, then only later:

```rust
.when_some(grid_config, |container, config| { ... })
```

If `build_component_bounds` does any non-trivial work (and it sounds like it does), you’re paying that cost on every frame even when `grid_config` is `None`. That’s a silent “why is my idle CPU high?” kind of issue.

**Fix:** Only compute bounds when `grid_config.is_some()`.

---

### 3) **`ctx.hide()` can hide the entire app; you don’t consistently route through your helper**

You clearly know `ctx.hide()` hides *all* windows (you even comment it), and you built `hide_main_window_helper` to avoid nuking Notes/AI windows.

But there are still paths that call `ctx.hide()` directly without checking other windows — for example in stdin key simulation:

```rust
// SimulateKey Escape branch
script_kit_gpui::set_main_window_visible(false);
ctx.hide();
```

If an automation uses stdin to simulate escape while Notes/AI are open, you risk hiding *everything*. The same kind of drift is likely elsewhere in the included files.

**Fix:** enforce “only hide via helper” as a rule. If you can’t call the helper from some context, refactor helper(s) so you can.

---

### 4) **Side effects in `render()`**

You do multiple stateful / effectful things inside `render()`:

* flushing toasts
* reading platform focus state and potentially closing/resetting the window
* re-focusing handles when “not focused”

GPUI is designed around effects being queued and flushed after updates (so you don’t get re-entrant chaos), which helps, but doing “policy decisions” in `render()` still causes hard-to-reason loops (focus thrash, repeated notify cycles, “why does focus keep stealing from my component?”). The GPUI model is: **render should map state → element tree; updates should mutate state**. The Zed team explicitly leans on queued effects to avoid reentrancy, but that’s about *dispatch order*, not “render is a good place to mutate.” ([Zed][1])

**Fix direction:** move focus enforcement / auto-dismiss into:

* a subscription/event handler (window focus events if you have them), or
* a periodic task, or
* an explicit “on_show / on_hide / on_view_enter” transition function

Render-time checks should ideally be read-only.

---

### 5) **Scheduler bun path code looks like it wants to borrow a temporary**

This block is suspicious enough that I’d treat it as a potential latent bug (or something that only “works” by accident):

```rust
for candidate in &[
  "/opt/homebrew/bin/bun",
  "/usr/local/bin/bun",
  std::env::var("HOME").ok()
      .map(|h| format!("{}/.bun/bin/bun", h))
      .unwrap_or_default()
      .as_str(),
] { ... }
```

That `as_str()` is a reference into a temporary `String`. If this compiled, it’s only because the compiler managed to extend the temporary’s lifetime in this context, which is brittle and easy to break during refactors.

**Fix:** build the home-based candidate as a `String` variable first, then check it, or use `PathBuf` and avoid `&str` shenanigans entirely.

---

## 2. Performance concerns

### 1) Polling loops that wake the runtime constantly

You have multiple “Timer + try_recv” loops:

* config watcher: every 200ms
* script watcher: every 200ms
* tray menu: every 100ms

On macOS, frequent wakeups are exactly how “idle” apps end up with measurable CPU + energy impact.

**Fix direction:** prefer event-driven `.recv().await` whenever possible. GPUI already supports event-driven subscriptions and notifications between entities (observe/notify and subscribe/emit). ([Docs.rs][2])
If your watcher uses `std::sync::mpsc`, consider switching it to `async_channel` (you already use it for prompt messages) so you can block efficiently.

---

### 2) Unbounded caches

`clipboard_image_cache: HashMap<String, Arc<gpui::RenderImage>>` will grow forever unless you trim it. If a user scrolls through a lot of clipboard image entries, you’re going to retain GPU images indefinitely.

**Fix:** LRU by entry id, with a cap in “items” *and* approximate bytes. Evict on view change or memory pressure.

---

### 3) Platform calls in the hot render loop

You call `platform::is_main_window_focused()` on every render. If that crosses the ObjC boundary / does window querying, it can add jitter.

**Fix:** observe focus changes rather than polling. If the platform layer can emit events, consume them. If not, poll at a lower rate (e.g., 100–200ms) and cache.

---

### 4) Data duplication via `AppView` variants

For AppLauncher you do `let apps = view.apps.clone();` and store it inside the view enum. That duplicates memory and creates coherency problems (“apps list updated in background but active view still has old copy”).

**Fix:** store apps once in a model; views reference it.

---

## 3. API design feedback

### 1) Replace `Arc<Mutex<...>>` shared state with GPUI events

You have several shared-state “escape hatches”:

* `pending_path_action: Arc<Mutex<Option<PathInfo>>>`
* `close_path_actions: Arc<Mutex<bool>>`
* `path_actions_showing: Arc<Mutex<bool>>`
* `path_actions_search_text: Arc<Mutex<String>>`
* `pending_path_action_result: Arc<Mutex<Option<(String, PathInfo)>>>`

That’s a sign the component boundaries aren’t aligned with GPUI’s communication primitives. GPUI provides:

* `notify/observe` for “something changed” ([Docs.rs][2])
* `emit/subscribe` for typed events ([Docs.rs][2])

If PathPrompt needs to tell the parent “open actions dialog” or “execute action X”, emit a typed event from PathPrompt and let the parent subscribe. That eliminates mutexes, reduces deadlock risk, and makes the data flow explicit.

---

### 2) Use GPUI global state for theme/config propagation

You want theme hot-reload “across all windows”. Right now you manually call `theme::sync_gpui_component_theme(cx)` + `view.update_theme(ctx)` etc.

GPUI supports app-level globals + `observe_global` (from the `App` API). ([Docs.rs][2])
A clean approach is:

* store theme/config in a `Global` struct
* when watcher fires: update global
* each window/view observes the global and refreshes

This removes a lot of per-window plumbing and ensures new windows get the latest theme automatically.

---

### 3) Centralize mutations behind a message dispatcher

Right now you have “call `cx.notify()` or UI goes stale” and 264 sites. That’s exactly what happens when you don’t have a single mutation choke point.

In GPUI terms, you can make your own Elm-like pattern: define an `enum Msg`, and make every event handler call `dispatch(msg, cx)`; `dispatch` is the *only* place you call `cx.notify()`.

This isn’t just aesthetic — it kills an entire class of “forgot notify” bugs.

GPUI’s model of queued effects makes this pattern behave predictably (listeners aren’t invoked immediately when you notify/emit). ([Zed][1])

---

## 4. Simplification opportunities

### 1) Split state into “model” vs “view state” vs “services”

Right now `ScriptListApp` holds everything: data, caches, UI focus, scroll, protocol channels, async subscriptions, preview cache, registries, etc.

A practical decomposition that fits GPUI well:

**A) `Entity<AppModel>` (data + revisions)**
Holds:

* scripts/scriptlets/apps
* registries (alias/shortcut/action_shortcuts)
* frecency store
* config + theme
* “revision counters” for invalidation

**B) Views (each as its own `Entity<...>` holding only view-local state)**

* `ScriptListView` (filter input, selection, main scroll, grouped results cache, etc.)
* `ClipboardHistoryView` (filter, selection, scroll; entries come from model or clipboard module)
* `AppLauncherView` (filter, selection, scroll; apps come from model)
* `WindowSwitcherView`
* `DesignGalleryView`
  Prompts are already heading this direction (many are `Entity<...>` in `AppView`).

**C) Services**

* executor / script session plumbing
* toast manager
* watchers / scheduler integration
  These can live in the app model or globals, but not in the main “render state bag”.

This alone will drop field count massively and reduce cross-coupling.

---

### 2) Replace magic cache keys with revision-based caches

String sentinels like `"\0_APPS_LOADED_\0"` are a smell because they’re **untyped dependency tracking**.

Instead:

* maintain `u64` revisions in the model: `scripts_rev`, `apps_rev`, `theme_rev`, etc.
* cache keys become small structs containing revisions + small inputs

This is faster than string keys and far less fragile.

---

### 3) Scroll handles: per-view is fine, but don’t keep them all in the root

Per-view scroll state is totally acceptable (it’s normal UI behavior). The problem is you’re managing 5+ handles and “last scrolled” duplication all in one place.

Put each scroll handle in the view that owns that list. If you truly need cross-view scroll behavior, centralize it in a `ScrollManager` struct keyed by an enum.

---

### 4) Focus state duplication: stop tracking it twice

You have:

* `FocusedInput` enum
* multiple `FocusHandle`s
* also booleans like `gpui_input_focused`

This is how focus bugs multiply. A better approach:

* one “desired focus target” enum, *or*
* no enum at all: derive cursor display from `is_focused(window)` checks of the handles you already have

---

## 5. Specific recommendations with concrete code

### A) Fix the `AppView` clone bomb immediately

**Goal:** stop cloning big vectors per frame.

Change these `AppView` variants from “owning data” to “owning view state only”.

Before:

```rust
AppView::ClipboardHistoryView {
  entries: Vec<ClipboardEntryMeta>,
  filter: String,
  selected_index: usize,
}
```

After:

```rust
enum AppView {
  ScriptList,
  ClipboardHistory(ClipboardHistoryState),
  AppLauncher(AppLauncherState),
  WindowSwitcher(WindowSwitcherState),
  DesignGallery(DesignGalleryState),
  // prompts already use Entity<...>
}

struct ClipboardHistoryState {
  filter: String,
  selected_index: usize,
  scroll: UniformListScrollHandle,
}
```

Then in render, fetch entries from a single source of truth (cache in model, or call into `clipboard_history`), and pass **references** into rendering.

This also sets you up to remove the `current_view.clone()` entirely.

---

### B) Implement a typed cache with revision dependencies (kills magic strings)

```rust
#[derive(Clone, PartialEq, Eq)]
struct GroupedDeps {
    filter: SharedString, // or String
    scripts_rev: u64,
    apps_rev: u64,
    design: DesignVariant,
}

struct Cache<D, V> {
    deps: Option<D>,
    value: V,
}

impl<D: PartialEq, V> Cache<D, V> {
    fn new(value: V) -> Self {
        Self { deps: None, value }
    }

    fn get_or_update(&mut self, deps: D, build: impl FnOnce() -> V) -> &V {
        let dirty = self.deps.as_ref().map_or(true, |old| old != &deps);
        if dirty {
            self.value = build();
            self.deps = Some(deps);
        }
        &self.value
    }
}
```

Now your grouped cache becomes:

```rust
// in view state
grouped_cache: Cache<GroupedDeps, Arc<[GroupedListItem]>>,
flat_cache: Cache<GroupedDeps, Arc<[SearchResult]>>,
```

No sentinels. No string keys. No accidental mismatch.

---

### C) Central “dispatch” + single notify point (Elm-ish)

```rust
enum Msg {
    SetFilter(SharedString),
    MoveSelection(i32),
    ExecuteSelected,
    ToggleActions,
    ViewChanged(AppView),
    // ...
}

impl ScriptListApp {
    fn dispatch(&mut self, msg: Msg, window: Option<&mut Window>, cx: &mut Context<Self>) {
        match msg {
            Msg::SetFilter(text) => {
                self.filter_text = text.to_string();
                self.selected_index = 0;
                self.invalidate_filter_caches(); // purely local
            }
            Msg::MoveSelection(delta) => self.move_selection(delta, cx),
            Msg::ExecuteSelected => self.execute_selected(cx),
            Msg::ToggleActions => if let Some(w) = window { self.toggle_actions(cx, w) },
            Msg::ViewChanged(view) => self.current_view = view,
        }

        cx.notify(); // <— one place
    }
}
```

Then all event handlers become:

```rust
let entity = cx.entity().downgrade();
div().on_click(move |_, window, cx| {
    if let Some(app) = entity.upgrade() {
        app.update(cx, |this, cx| this.dispatch(Msg::ExecuteSelected, Some(window), cx));
    }
})
```

This won’t give true compile-time enforcement, but it cuts the surface area where you can forget notify from ~264 sites to “almost none”.

GPUI’s `notify/emit` being queued (not re-entrant) makes this style predictable. ([Zed][1])

---

### D) Reduce clone pressure in closures: capture IDs, not lists

Instead of cloning `Arc<[GroupedListItem]>` just to build click handlers, capture:

* `script_path: SharedString` or
* `Arc<Script>` (cheap clone)

and do lookups in the update closure.

This is where GPUI’s “keep an entity reference alive to keep state alive” guidance matters — don’t recreate models/views each frame; store them once and keep handles. ([GitHub][3])

---

### E) Replace `Arc<Mutex<...>>` cross-component wiring with typed events

For PathPrompt → parent communication:

```rust
enum PathPromptEvent {
    ToggleActions,
    Chosen(PathInfo),
    Cancel,
}

impl gpui::EventEmitter<PathPromptEvent> for PathPrompt {}
```

Then in parent:

```rust
let sub = cx.subscribe(&path_prompt_entity, |app, event, cx| {
    app.update(cx, |this, cx| {
        match event {
            PathPromptEvent::ToggleActions => this.show_actions_popup = true,
            PathPromptEvent::Chosen(info) => this.handle_path(info.clone(), cx),
            PathPromptEvent::Cancel => this.reset_to_script_list(cx),
        }
        cx.notify();
    });
});
self.subscriptions.push(sub);
```

GPUI’s `subscribe` API is designed exactly for this. ([Docs.rs][2])

---

## Answers to your “Expert Questions” (direct)

### 1) Should you split `ScriptListApp` into smaller views?

Yes. Not “because it’s prettier” — because you currently can’t stop state from cross-contaminating, and you’re already paying for it (notify spam, cache hacks, borrow-checker workarounds, duplicated focus/scroll).

GPUI composition wants you to **create views/models once and keep references alive**; if you create them transiently, they get dropped and lose state. ([GitHub][3])
So: create sub-views as entities during initialization or on transition, store them, and render them as children.

### 2) Pattern to auto-notify like Elm?

There’s no magic compiler enforcement, but you can get 90% of the value with:

* a single `dispatch(Msg, ...)` function that always notifies
* (optional) a `mutate(|this| ...)` helper that always notifies

Also: GPUI provides `observe/notify` and `subscribe/emit` so you can stop using shared mutex state and manual invalidation. ([Docs.rs][2])

### 3) Idiomatic parent/child shared state?

Use one of these (in order of “GPUI-native”):

1. **Child emits typed events; parent subscribes** (best for UI interactions). ([Docs.rs][2])
2. **Parent owns a model entity; children read/update via entity handles**.
3. **App globals** for cross-window state like theme/config. ([Docs.rs][2])

Avoid `Arc<Mutex<...>>` unless you *truly* need cross-thread sharing and there’s no event boundary.

### 4) Single source of truth for scroll state?

Per-view scroll is fine. What’s *not* fine is managing all scroll handles in the root view. Put scroll handles in the view that owns the list. If you need persistence across view switches, keep the view entity alive (don’t recreate it).

### 5) How do large GPUI apps (Zed) manage this?

They lean heavily on:

* clear separation between models and views
* reference-counted ownership: state persists only if something holds a handle to it ([GitHub][3])
* observe/notify for coarse invalidation and subscribe/emit for typed event flow ([Docs.rs][2])
* keeping “big state” out of the render loop and avoiding per-frame allocations/clones

---

## What I’d do first (highest ROI sequence)

1. **Stop cloning big vectors per render**: redesign `AppView` variants so they don’t own bulk data.
2. **Introduce a `dispatch(Msg)`** and route UI mutations through it → kill 90% of notify bugs.
3. **Replace string cache keys with revision-based typed deps**.
4. **Move per-view scroll/focus/caches into per-view entities**.
5. **Replace shared `Arc<Mutex<...>>` wiring with typed events** (`emit/subscribe`).

If you do only #1 + #2, you’ll feel an immediate improvement in both performance and debuggability.

[1]: https://zed.dev/blog/gpui-ownership?utm_source=chatgpt.com "Ownership and data flow in GPUI — Zed's Blog"
[2]: https://docs.rs/gpui/latest/gpui/struct.App.html?utm_source=chatgpt.com "App in gpui - Rust"
[3]: https://github.com/zed-industries/zed/discussions/7120 "How do I create a new_view inside a component in GPUI? · zed-industries zed · Discussion #7120 · GitHub"
